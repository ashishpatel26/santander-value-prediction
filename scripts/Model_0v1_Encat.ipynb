{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 0 Model: Encoding with CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row-wise metadata generator\n",
    "def generate_meta(df):\n",
    "    meta = pd.DataFrame({\n",
    "        'nonsparse_count': (df[df==-1]+1).fillna(1).sum(axis=1),\n",
    "        'mean': df[df!=-1].mean(axis=1),\n",
    "        'std': df[df!=-1].std(axis=1),\n",
    "        'median': df[df!=-1].median(axis=1),\n",
    "        'max': df[df!=-1].max(axis=1),\n",
    "        'min': df[df!=-1].min(axis=1),\n",
    "        'var': df[df!=-1].var(axis=1)})\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original train and test datasets...\n",
      "Loading completed in 54.9546971321 seconds\n"
     ]
    }
   ],
   "source": [
    "load_start = time.time()\n",
    "data_path = '../data/'\n",
    "print 'Loading original train and test datasets...'\n",
    "train_df = pd.read_csv(data_path + 'train.csv')\n",
    "test_df = pd.read_csv(data_path + 'test.csv')\n",
    "print 'Loading completed in %s seconds'%(time.time()-load_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata data path\n",
    "meta_path = data_path + 'meta_stage0v1.csv'\n",
    "# Autoencoder data path\n",
    "auto_type = '155'\n",
    "autodir_path = './autoencoder/data/'\n",
    "autotrain_path = autodir_path + 'train_' + auto_type + '.csv'\n",
    "autotest_path = autodir_path + 'test_' + auto_type + '.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some data preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with constant terms (aka standard dev == 0)\n",
    "std_df = train_df.std(axis=0)\n",
    "drop_cols = std_df[std_df==0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format label values\n",
    "Y = np.log1p(train_df.target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test ID values\n",
    "ID = test_df.ID.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop target and ID columns\n",
    "train_df.drop(columns=['ID', 'target'], axis=1, inplace=True)\n",
    "test_df.drop(columns=['ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master dataset and perform scaling \n",
    "X = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "scaled_X = X.div(X.max(), axis='columns')\n",
    "scaled_X[scaled_X==0.0] = -1.0\n",
    "# Scale labels\n",
    "y_min = np.min(Y)\n",
    "y_max = np.max(Y)\n",
    "scaled_Y = (Y - y_min)/(y_max - y_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get autoencoder and metadata results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder data\n",
    "autotrain = pd.read_csv(autotrain_path, index_col=0)\n",
    "autotest = pd.read_csv(autotest_path, index_col=0)\n",
    "auto_all = pd.concat([autotrain, autotest], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row-wise metadata\n",
    "if not os.path.exists(meta_path):\n",
    "    print 'Generating row-wise metadata...'\n",
    "    meta_X = generate_meta(scaled_X)\n",
    "    meta_X.to_csv(meta_path, index=False)\n",
    "else:\n",
    "    print 'Loading row-wise metadata...'\n",
    "    meta_X = read_csv(meta_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Encodings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=0\n",
    "num_clusters1 = 24\n",
    "num_clusters2 = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Mini-Batch KMeans...\n",
      "Running PCA...\n",
      "Running Truncated SVD...\n",
      "Running Gaussian Random Projection...\n",
      "Running Sparse Random Projection...\n"
     ]
    }
   ],
   "source": [
    "print 'Running Mini-Batch KMeans...'\n",
    "mbkm = MiniBatchKMeans(n_clusters=num_clusters2, random_state=random_state)\n",
    "mbkm_X = pd.DataFrame(mbkm.fit_transform(scaled_X))\n",
    "print 'Running PCA...'\n",
    "pca = PCA(n_components=num_clusters2, random_state=random_state)\n",
    "pca_X = pd.DataFrame(pca.fit_transform(scaled_X))\n",
    "print 'Running Truncated SVD...'\n",
    "tsvd = TruncatedSVD(n_components=num_clusters2, random_state=random_state)\n",
    "tsvd_X = pd.DataFrame(tsvd.fit_transform(scaled_X))\n",
    "print 'Running Gaussian Random Projection...'\n",
    "grp = GaussianRandomProjection(n_components=num_clusters1, eps=0.1, random_state=random_state)\n",
    "grp_X = pd.DataFrame(grp.fit_transform(scaled_X))\n",
    "print 'Running Sparse Random Projection...'\n",
    "srp = SparseRandomProjection(n_components=num_clusters1, dense_output=True, random_state=random_state)\n",
    "srp_X = pd.DataFrame(srp.fit_transform(scaled_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
